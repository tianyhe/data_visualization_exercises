{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization with Plotly (HTML output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[5, 2, 4, 4, 2, 5, 4, 5, 4, 5, 1, 3, 6, 5, 2, 4, 1, 2, 5, 4, 6, 1, 5, 1, 6, 1, 2, 1, 5, 6, 1, 2, 3, 1, 5, 6, 6, 4, 3, 1, 6, 2, 4, 3, 5, 4, 3, 6, 6, 4, 4, 4, 4, 3, 4, 6, 6, 5, 4, 2, 2, 1, 2, 2, 3, 4, 3, 4, 2, 3, 1, 3, 3, 2, 3, 5, 1, 1, 3, 6, 6, 1, 4, 6, 3, 5, 6, 4, 5, 6, 5, 3, 6, 4, 5, 5, 1, 1, 6, 6]\n[16, 13, 15, 20, 17, 19]\n"
    }
   ],
   "source": [
    "\"\"\"Die\"\"\"\n",
    "from random import randint\n",
    "\n",
    "from plotly.graph_objs import Bar, Layout\n",
    "from plotly import offline\n",
    "\n",
    "class Die:\n",
    "    \"\"\"A class representing a sigle die.\"\"\"\n",
    "\n",
    "    def __init__(self, num_sides=6):\n",
    "        \"\"\"Initialize attributes of the die.\"\"\"\n",
    "        self.num_sides = num_sides\n",
    "        self.results = 0\n",
    "        self.frequencies = 0\n",
    "\n",
    "    def roll(self):\n",
    "        \"\"\"Return a random value between 1 and number of sides.\"\"\"\n",
    "        return randint(1, self.num_sides)\n",
    "\n",
    "    def mult_roll(self, numbers_roll=1):\n",
    "        \"\"\"Return results of x times rolling in a list.\"\"\"\n",
    "        self.numbers_roll = numbers_roll\n",
    "        self.results = [self.roll() for num_roll in range(numbers_roll)]\n",
    "        return self.results\n",
    "\n",
    "    def frequency(self):\n",
    "        \"\"\"\n",
    "        Count the frequency of each side with given results.\n",
    "        \"\"\"\n",
    "        self.frequencies = [\n",
    "            self.results.count(value) for value in range(1, self.num_sides + 1)\n",
    "            ]\n",
    "        return self.frequencies\n",
    "\n",
    "    def one_die_histogram(self):\n",
    "        \"\"\"After rolling the die, visualize the results of the die roll.\"\"\"\n",
    "        x_values = list(range(1, self.num_sides + 1))\n",
    "        data = [Bar(x=x_values, y=self.frequencies)]\n",
    "\n",
    "        x_axis_config = {'title': 'Result'}\n",
    "        y_axis_config = {'title': 'Frequencies'}\n",
    "        my_layout = Layout(\n",
    "            title=f\"Results of rolling one D{self.num_sides} {self.numbers_roll} times\",\n",
    "            xaxis=x_axis_config, yaxis=y_axis_config\n",
    "            )\n",
    "        offline.plot(\n",
    "            {'data':data, 'layout':my_layout},\n",
    "            filename=f\"d{self.num_sides}.html\"\n",
    "            )\n",
    "\n",
    "# Plotting\n",
    "# D6 = Die(6)\n",
    "# results = D6.mult_roll(100)\n",
    "# print(results)\n",
    "# freq = D6.frequency()\n",
    "# print(freq)\n",
    "# D6.one_die_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dice\"\"\"\n",
    "from random import randint\n",
    "\n",
    "from plotly.graph_objs import Bar, Layout\n",
    "from plotly import offline\n",
    "\n",
    "#from die import Die\n",
    "\n",
    "class Dice:\n",
    "    \"\"\"A class respresent multple dices.\"\"\"\n",
    "\n",
    "    def __init__(self, num_sides):\n",
    "        \"\"\"Initialize attributes of multiple dice.\"\"\"\n",
    "        self.num_dice = len(num_sides) # number of dice.\n",
    "        self.num_sides = num_sides # number of sides for each dice in a list.\n",
    "        self.dice = self._create_dice() # a set of dice in a list.\n",
    "\n",
    "        self.numbers_roll = 0\n",
    "        self.results = []\n",
    "        self.frequencies = []\n",
    "        self.max_results = sum(self.num_sides)\n",
    "\n",
    "    def _create_dice(self):\n",
    "        \"\"\"Create all the dice instance.\"\"\"\n",
    "        dice = [Die(self.num_sides[num]) for num in range(self.num_dice)]\n",
    "        return dice\n",
    "\n",
    "    def roll_all(self):\n",
    "        \"\"\"Return a sum of value generated by rolling all the dices once.\"\"\"\n",
    "        results = [self.dice[num].roll() for num in range(self.num_dice)]\n",
    "        return sum(results)\n",
    "\n",
    "    def multi_roll_all(self, numbers_roll=2):\n",
    "        \"\"\"Return the results of rolling all the dice at once,\n",
    "        and roll for x times in a list.\n",
    "        \"\"\"\n",
    "        self.numbers_roll = numbers_roll\n",
    "        self.results = [self.roll_all() for roll_num in range(numbers_roll)]\n",
    "        return self.numbers_roll, self.results\n",
    "\n",
    "    def frequency(self):\n",
    "        \"\"\"Count the frequency of the dice roll outcome.\"\"\"\n",
    "        self.frequencies = [\n",
    "            self.results.count(value)\n",
    "            for value in range(self.num_dice, self.max_results + 1)\n",
    "            ]\n",
    "        return self.frequencies\n",
    "\n",
    "    def dice_histogram(self):\n",
    "        \"\"\"Visualize the results of the dice roll.\"\"\"\n",
    "        x_values = list(range(self.num_dice, self.max_results + 1))\n",
    "        y_values = [Bar(x=x_values, y=self.frequencies)]\n",
    "\n",
    "        x_axis_config = {'title': 'Result', 'dtick': 1}\n",
    "        y_axis_config = {'title': 'Frequencies'}\n",
    "        my_layout = Layout(\n",
    "            title=f\"Results of rolling D{self.num_sides} {self.numbers_roll} times\",\n",
    "            xaxis=x_axis_config, yaxis=y_axis_config\n",
    "            )\n",
    "        offline.plot(\n",
    "            {'data':y_values, 'layout':my_layout},\n",
    "            filename=\"results.html\"\n",
    "            )# # # # # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earthquake Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Earthquake Explore\"\"\"\n",
    "import json\n",
    "import re\n",
    "\n",
    "from plotly.graph_objs import Scattergeo, Layout\n",
    "from plotly import offline\n",
    "\n",
    "def main(input_file_path, output_file_path):\n",
    "    \"\"\"Visualize earthquake data with geoJson data.\"\"\"\n",
    "    # Explore the structure of the data\n",
    "    filename = input_file_path\n",
    "    with open(filename) as fhand:\n",
    "        all_eq_data = json.load(fhand)\n",
    "\n",
    "    readable_file = 'earthquake/data/readable_eq_data.json'\n",
    "    with open(readable_file, 'w') as fhand:\n",
    "        json.dump(all_eq_data, fhand, indent=4)\n",
    "\n",
    "    all_eq_dicts = all_eq_data['features']\n",
    "    #print(len(all_eq_dicts)) # numbers of earthquake records\n",
    "    title = all_eq_data['metadata']['title']\n",
    "\n",
    "    hover_texts = [eq_dict['properties']['title'] for eq_dict in all_eq_dicts]\n",
    "    mags = [eq_dict['properties']['mag'] for eq_dict in all_eq_dicts]\n",
    "    lons = [eq_dict['geometry']['coordinates'][0] for eq_dict in all_eq_dicts]\n",
    "    lats = [eq_dict['geometry']['coordinates'][1] for eq_dict in all_eq_dicts]\n",
    "\n",
    "    #Map the earthquake\n",
    "    data = [{\n",
    "        'type': 'scattergeo',\n",
    "        'lon': lons,\n",
    "        'lat': lats,\n",
    "        'text': hover_texts,\n",
    "        'marker': {\n",
    "            'size': [5*mag for mag in mags], # Set the size of marker based on mag\n",
    "            'color': mags,\n",
    "            'colorscale': 'Agsunset',\n",
    "            'reversescale': True,\n",
    "            'colorbar': {'title': 'Magnitude'},\n",
    "        },\n",
    "    }]\n",
    "    my_layout = Layout(title=f'{title}')\n",
    "\n",
    "    fig = {'data': data, 'layout': my_layout}\n",
    "    offline.plot(fig, filename=output_file_path)\n",
    "\n",
    "# input_file_path = 'earthquake/data/m4.5+_eq_data_past_month.json'\n",
    "# output_file_path = 'earthquake/output/global_m4.5+_earthquakes_past_month.html'\n",
    "# main(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Python Project Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Github Python Project Visualization\"\"\"\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objs import Bar\n",
    "from plotly import offline\n",
    "\n",
    "import hidden # import personal access token\n",
    "\n",
    "def main(search_url, headers):\n",
    "    \"\"\"Visualize the Most-Starred Python Projects on Github.\"\"\"\n",
    "    # Make an API call to store the response.\n",
    "    r = requests.get(search_url, headers=headers)\n",
    "    print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "    # Store API response in a variable\n",
    "    response_dict = r.json()\n",
    "\n",
    "    # # Process results.\n",
    "    # print(response_dict.keys())\n",
    "\n",
    "    # Explore information about the repositories.\n",
    "    repo_dicts = response_dict['items']\n",
    "    print(f\"Repositories returned: {len(repo_dicts)}\")\n",
    "\n",
    "    # Summary for the repositories.\n",
    "    # print(\"\\nSelected information about each repository:\")\n",
    "    # for repo_dict in repo_dicts:\n",
    "    #     print(f\"Name: {repo_dict['name']}\")\n",
    "    #     print(f\"Owner: {repo_dict['owner']['login']}\")\n",
    "    #     print(f\"Stars: {repo_dict['stargazers_count']}\")\n",
    "    #     print(f\"Repository: {repo_dict['html_url']}\")\n",
    "    #     print(f\"Created: {repo_dict['created_at']}\")\n",
    "    #     print(f\"Updated: {repo_dict['updated_at']}\")\n",
    "    #     print(f\"Description: {repo_dict['description']}\\n\")\n",
    "\n",
    "    repo_links, stars, labels = [], [], []\n",
    "    for repo_dict in repo_dicts:\n",
    "        # x_axis\n",
    "        repo_name = repo_dict['name']\n",
    "        repo_url = repo_dict['html_url']\n",
    "        repo_link = f\"<a href='{repo_url}'>{repo_name}</a>\"\n",
    "        repo_links.append(repo_link)\n",
    "        # y_axis\n",
    "        stars.append(repo_dict['stargazers_count'])\n",
    "        # hover_text\n",
    "        owner = repo_dict['owner']['login']\n",
    "        description = repo_dict['description']\n",
    "        label = f\"{owner}<br />{description}\"\n",
    "        labels.append(label)\n",
    "\n",
    "    # Make Visualization\n",
    "    data = [{\n",
    "        'type': 'bar',\n",
    "        'x': repo_links,\n",
    "        'y': stars,\n",
    "        'hovertext': labels,\n",
    "        'marker': {\n",
    "            'color': 'rgb(60, 100, 150)',\n",
    "            'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "        },\n",
    "        'opacity': 0.6,\n",
    "    }]\n",
    "\n",
    "    my_layout = {\n",
    "        'title': 'Most-Starred Python Projects on Github',\n",
    "        'titlefont': {'size': 28},\n",
    "        'xaxis': {\n",
    "            'title': 'Repository',\n",
    "            'titlefont': {'size': 24},\n",
    "            'tickfont': {'size': 14},\n",
    "        },\n",
    "        'yaxis': {\n",
    "            'title': 'Stars',\n",
    "            'titlefont': {'size': 24},\n",
    "            'tickfont': {'size': 14},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    fig = {'data': data, 'layout': my_layout}\n",
    "    offline.plot(fig, filename='github_visual/python_repos.html')\n",
    "\n",
    "def rate_limit(rate_url, headers):\n",
    "    \"\"\"Check the remaining rate limit for search.\"\"\"\n",
    "    r_rate = requests.get(rate_url, headers=headers)\n",
    "    rate_dict = r_rate.json()\n",
    "    rate_remaining = rate_dict['resources']['search']['remaining']\n",
    "    print(f\"Remaining Rate: {rate_remaining}\")\n",
    "\n",
    "search_url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "rate_url = 'https://api.github.com/rate_limit'\n",
    "headers = {\n",
    "    'Accept': 'application/vnd.github.vs+json',\n",
    "    'Authorization': 'token ' + f'{hidden.token_secret()}'\n",
    "    }\n",
    "\n",
    "main(search_url, headers)\n",
    "rate_limit(rate_url, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Fire Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"World Fire\"\"\"\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "from plotly.graph_objs import Scattergeo, Layout\n",
    "from plotly import offline\n",
    "\n",
    "def main(input_file_path, output_file_path):\n",
    "    \"\"\"Visualize global fire data with csv files.\"\"\"\n",
    "    filename = input_file_path\n",
    "    fhand = open(filename)\n",
    "    reader = csv.reader(fhand)\n",
    "    header_row = next(reader)\n",
    "\n",
    "    header= {}\n",
    "    for index, column_header in enumerate(header_row):\n",
    "        header[column_header] = index\n",
    "\n",
    "    lats, lons, brightnesses, hover_texts = [], [], [], []\n",
    "    for row in reader:\n",
    "        try:\n",
    "            lat = float(row[header['latitude']])\n",
    "            lon = float(row[header['longitude']])\n",
    "            brightness = float(row[header['brightness']])\n",
    "            hover_text = f\"{row[header['acq_date']]}, {row[header['acq_time']]}, \"\n",
    "            hover_text += f\" {row[header['daynight']]}\"\n",
    "        except ValueError:\n",
    "            print(f\"Missing data for {row[header['acq_date']]}\")\n",
    "        else:\n",
    "            lats.append(lat)\n",
    "            lons.append(lon)\n",
    "            brightnesses.append(brightness)\n",
    "            hover_texts.append(hover_text)\n",
    "\n",
    "    #Map the earthquake\n",
    "    data = [{\n",
    "        'type': 'scattergeo',\n",
    "        'lon': lons,\n",
    "        'lat': lats,\n",
    "        'text': hover_texts,\n",
    "        'marker': {\n",
    "            #'size': [0.1*brightness for brightness in brightnesses],\n",
    "            'color': brightnesses,\n",
    "            'colorscale': 'Agsunset',\n",
    "            'reversescale': True,\n",
    "            'colorbar': {'title': 'Brightness'},\n",
    "        },\n",
    "    }]\n",
    "    my_layout = Layout(title='Global Active Fire Past Day')\n",
    "\n",
    "    fig = {'data': data, 'layout': my_layout}\n",
    "    offline.plot(fig, filename=output_file_path)\n",
    "    fhand.close()\n",
    "\n",
    "# input_file_path = 'global_fire/data/MODIS_C6_Global_24h.csv'\n",
    "# output_file_path = 'global_fire/output/global_fire_past_day.html'\n",
    "# main(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacker News API data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "Explore the structure of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hacker News API\"\"\"\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://hacker-news.firebaseio.com/v0/item/19155826.json'\n",
    "r = requests.get(url)\n",
    "print(f\"Status Code: {r.status_code}\")\n",
    "\n",
    "# Explore the structure of the data.\n",
    "response_dict = r.json()\n",
    "readable_file = 'hacker_news_visual/data/readable_hn_data.json'\n",
    "with open(readable_file, 'w') as fhand:\n",
    "    json.dump(response_dict, fhand, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hacker News API\"\"\"\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "def main(url):\n",
    "    \"\"\"Save the most active discussion on Hacker News in json.\"\"\"\n",
    "    # Make an API call to store the response.\n",
    "    id_url = url\n",
    "    response_obj = requests.get(id_url)\n",
    "    print(f\"Status Code: {response_obj.status_code}\")\n",
    "\n",
    "    # Process information about each submission.\n",
    "    submission_ids = response_obj.json()\n",
    "    print(f\"Retrieved ids: {len(submission_ids)}\\n\")\n",
    "    submission_dicts = []\n",
    "\n",
    "    for submission_id in submission_ids[:50]:\n",
    "        # Make a seperate API call for each submission.\n",
    "        url = f\"https://hacker-news.firebaseio.com/v0/item/{submission_id}.json\"\n",
    "        response_obj = requests.get(url)\n",
    "        print(f\"id: {submission_id}\\tStatus Code: {response_obj.status_code}\")\n",
    "        response_dict = response_obj.json()\n",
    "\n",
    "        try:\n",
    "            # Build a dictionary for each article.\n",
    "            submission_dict = {\n",
    "                'title': response_dict['title'],\n",
    "                'hn_link': f\"https://news.ycombinator.com/item?id={submission_id}\",\n",
    "                'comments': response_dict['descendants'],\n",
    "            }\n",
    "            submission_dicts.append(submission_dict)\n",
    "        except KeyError:\n",
    "            print(f\"Failure to Find the corresponding key: {submission_id}\")\n",
    "            continue\n",
    "\n",
    "    submission_dicts = sorted(\n",
    "        submission_dicts, key=itemgetter('comments'), reverse=True)\n",
    "\n",
    "    for submission_dict in submission_dicts:\n",
    "        print(f\"\\nTitle: {submission_dict['title']}\")\n",
    "        print(f\"Discussion Links: {submission_dict['hn_link']}\")\n",
    "        print(f\"Comments: {submission_dict['comments']}\")\n",
    "\n",
    "    # Save the retrieved data in json file.\n",
    "    saved_file = 'hacker_news/data/submissions.json'\n",
    "    with open(saved_file, 'w') as fhand:\n",
    "        json.dump(submission_dicts, fhand)\n",
    "\n",
    "URL = 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "main(URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize the Hacker News Data\"\"\"\n",
    "import json\n",
    "\n",
    "from plotly.graph_objs import Bar\n",
    "from plotly import offline\n",
    "\n",
    "def main(input_file_path, output_file_path):\n",
    "    \"\"\"Visualize retrieved Hacker News data.\"\"\"\n",
    "    file_path = input_file_path\n",
    "    submission_dicts = []\n",
    "    with open(file_path) as fhand:\n",
    "        submission_dicts = json.load(fhand)\n",
    "\n",
    "    labels, comments = [], []\n",
    "    for submission_dict in submission_dicts:\n",
    "        # x_axis\n",
    "        title = submission_dict['title']\n",
    "        hn_link = submission_dict['hn_link']\n",
    "        label = f\"<a href='{hn_link}'>{title}</a>\"\n",
    "        labels.append(label)\n",
    "        # y_axis\n",
    "        comments.append(submission_dict['comments'])\n",
    "\n",
    "    # Make Visualization\n",
    "    data = [{\n",
    "        'type': 'bar',\n",
    "        'x': labels,\n",
    "        'y': comments,\n",
    "        'marker': {\n",
    "            'color': 'rgb(60, 100, 150)',\n",
    "            'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "        },\n",
    "        'opacity': 0.6,\n",
    "    }]\n",
    "\n",
    "    my_layout = {\n",
    "        'title': 'Most-Active Discussion on Hacker News',\n",
    "        'titlefont': {'size': 28},\n",
    "        'xaxis': {\n",
    "            'title': 'Repository',\n",
    "            'titlefont': {'size': 24},\n",
    "            'tickfont': {'size': 10},\n",
    "        },\n",
    "        'yaxis': {\n",
    "            'title': 'Stars',\n",
    "            'titlefont': {'size': 24},\n",
    "            'tickfont': {'size': 14},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    fig = {'data': data, 'layout': my_layout}\n",
    "    offline.plot(fig, filename=output_file_path)\n",
    "\n",
    "INPUT_FILE_PATH = 'hacker_news/data/submissions.json'\n",
    "OUTPUT_FILE_PATH = 'hacker_news/hacker_news.html'\n",
    "main(INPUT_FILE_PATH, OUTPUT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hacker News API\"\"\"\n",
    "from operator import itemgetter\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('hacker_news/data/submissions.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Make some fresh tables using executescript()\n",
    "cur.executescript('''\n",
    "DROP TABLE IF EXISTS Submissions;\n",
    "\n",
    "CREATE TABLE Submissions (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    submission_id  TEXT UNIQUE,\n",
    "    title TEXT  UNIQUE,\n",
    "    discussion_link TEXT UNIQUE,\n",
    "    comments INTEGER\n",
    ");\n",
    "''')\n",
    "\n",
    "# Make an API call to store the response.\n",
    "id_url = 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "r = requests.get(id_url)\n",
    "print(f\"Status Code: {r.status_code}\")\n",
    "\n",
    "# Process information about each submission.\n",
    "submission_ids = r.json()\n",
    "print(f\"Retrieved ids: {len(submission_ids)}\\n\")\n",
    "submission_dicts = []\n",
    "count = 1\n",
    "\n",
    "for submission_id in submission_ids[:50]:\n",
    "    # Make a seperate API call for each submission.\n",
    "    url = f\"https://hacker-news.firebaseio.com/v0/item/{submission_id}.json\"\n",
    "    r = requests.get(url)\n",
    "    print(f\"{count} - id: {submission_id}\\tStatus Code: {r.status_code}\")\n",
    "    response_dict = r.json()\n",
    "\n",
    "    try:\n",
    "        # Build a dictionary for each article.\n",
    "        submission_dict = {\n",
    "            'title': response_dict['title'],\n",
    "            'hn_link': f\"https://news.ycombinator.com/item?id={submission_id}\",\n",
    "            'comments': response_dict['descendants'],\n",
    "        }\n",
    "        submission_dicts.append(submission_dict)\n",
    "    except KeyError:\n",
    "        print(f\"Failure to Find the corresponding key: {submission_id}\")\n",
    "        continue\n",
    "    else:\n",
    "        cur.execute(\n",
    "            '''INSERT OR REPLACE INTO Submissions\n",
    "            (submission_id, title, discussion_link, comments)\n",
    "            VALUES ( ?, ?, ?, ? )''',\n",
    "            (submission_id, submission_dict['title'], submission_dict['hn_link'], submission_dict['comments']))\n",
    "\n",
    "    count += 1\n",
    "    if count % 5 == 0:\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitanaconda3virtualenvedc40d8526804069a338400f0dbc31c9",
   "display_name": "Python 3.7.7 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}